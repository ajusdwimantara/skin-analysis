{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59cea5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-27 13:47:21.974091: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1751006842.027325  101050 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1751006842.043341  101050 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1751006842.152365  101050 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751006842.152418  101050 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751006842.152426  101050 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751006842.152435  101050 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-06-27 13:47:22.166717: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/ajusd/anaconda3/envs/py310/lib/python3.10/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b4f34e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>image_001.jpg</td>\n",
       "      <td>acne;oily</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>image_002.jpg</td>\n",
       "      <td>acne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>image_003.jpg</td>\n",
       "      <td>acne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>image_004.jpg</td>\n",
       "      <td>acne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>image_005.jpg</td>\n",
       "      <td>acne</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        filename      label\n",
       "0  image_001.jpg  acne;oily\n",
       "1  image_002.jpg       acne\n",
       "2  image_003.jpg       acne\n",
       "3  image_004.jpg       acne\n",
       "4  image_005.jpg       acne"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load CSV\n",
    "df = pd.read_csv(\"multi_label_dataset.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eabfd173",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "      <th>label_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>image_001.jpg</td>\n",
       "      <td>acne;oily</td>\n",
       "      <td>[acne, oily]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>image_002.jpg</td>\n",
       "      <td>acne</td>\n",
       "      <td>[acne]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>image_003.jpg</td>\n",
       "      <td>acne</td>\n",
       "      <td>[acne]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>image_004.jpg</td>\n",
       "      <td>acne</td>\n",
       "      <td>[acne]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>image_005.jpg</td>\n",
       "      <td>acne</td>\n",
       "      <td>[acne]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        filename      label    label_list\n",
       "0  image_001.jpg  acne;oily  [acne, oily]\n",
       "1  image_002.jpg       acne        [acne]\n",
       "2  image_003.jpg       acne        [acne]\n",
       "3  image_004.jpg       acne        [acne]\n",
       "4  image_005.jpg       acne        [acne]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split label strings into lists\n",
    "df['label_list'] = df['label'].apply(lambda x: x.split(';'))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7607d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   acne  darkspot  dry  normal  oily  other  wrinkle\n",
      "0     1         0    0       0     1      0        0\n",
      "1     1         0    0       0     0      0        0\n",
      "2     1         0    0       0     0      0        0\n",
      "3     1         0    0       0     0      0        0\n",
      "4     1         0    0       0     0      0        0\n"
     ]
    }
   ],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "Y = mlb.fit_transform(df['label_list'])\n",
    "\n",
    "# Optional: convert back to DataFrame for visibility\n",
    "label_df = pd.DataFrame(Y, columns=mlb.classes_)\n",
    "print(label_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56eac24c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "      <th>label_list</th>\n",
       "      <th>filepath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>image_001.jpg</td>\n",
       "      <td>acne;oily</td>\n",
       "      <td>[acne, oily]</td>\n",
       "      <td>dataset/image_001.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>image_002.jpg</td>\n",
       "      <td>acne</td>\n",
       "      <td>[acne]</td>\n",
       "      <td>dataset/image_002.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>image_003.jpg</td>\n",
       "      <td>acne</td>\n",
       "      <td>[acne]</td>\n",
       "      <td>dataset/image_003.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>image_004.jpg</td>\n",
       "      <td>acne</td>\n",
       "      <td>[acne]</td>\n",
       "      <td>dataset/image_004.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>image_005.jpg</td>\n",
       "      <td>acne</td>\n",
       "      <td>[acne]</td>\n",
       "      <td>dataset/image_005.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        filename      label    label_list               filepath\n",
       "0  image_001.jpg  acne;oily  [acne, oily]  dataset/image_001.jpg\n",
       "1  image_002.jpg       acne        [acne]  dataset/image_002.jpg\n",
       "2  image_003.jpg       acne        [acne]  dataset/image_003.jpg\n",
       "3  image_004.jpg       acne        [acne]  dataset/image_004.jpg\n",
       "4  image_005.jpg       acne        [acne]  dataset/image_005.jpg"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store full image paths\n",
    "df['filepath'] = df['filename'].apply(lambda x: os.path.join('dataset', x))\n",
    "\n",
    "# Split into train/val\n",
    "X_train, X_val, y_train, y_val = train_test_split(df['filepath'], Y, test_size=0.2, random_state=42)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9b843ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store full image paths\n",
    "df['filepath'] = df['filename'].apply(lambda x: os.path.join('dataset', x))\n",
    "\n",
    "# Split into train/val\n",
    "X_train, X_val, y_train, y_val = train_test_split(df['filepath'], Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf26d221",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60bcc284",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1751006845.946083  101050 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2279 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Function to load and preprocess image\n",
    "def load_image(img_path, label):\n",
    "    img = tf.io.read_file(img_path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(img, IMG_SIZE)\n",
    "    img = img / 255.0\n",
    "    return img, label\n",
    "\n",
    "# Build tf.data.Dataset\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((X_train.values, y_train))\n",
    "train_ds = train_ds.map(load_image).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((X_val.values, y_val))\n",
    "val_ds = val_ds.map(load_image).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ad604e",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99a92fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.MobileNetV2(\n",
    "    input_shape=(224, 224, 3),\n",
    "    include_top=False,\n",
    "    weights='imagenet'\n",
    ")\n",
    "base_model.trainable = False\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    base_model,\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(len(mlb.classes_), activation='sigmoid')  # Multi-label output\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])  # For multi-label, you can also add AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b57fc501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ mobilenetv2_1.00_224            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">163,968</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">903</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ mobilenetv2_1.00_224            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1280\u001b[0m)     │     \u001b[38;5;34m2,257,984\u001b[0m │\n",
       "│ (\u001b[38;5;33mFunctional\u001b[0m)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m163,968\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │           \u001b[38;5;34m903\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,422,855</span> (9.24 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,422,855\u001b[0m (9.24 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">164,871</span> (644.03 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m164,871\u001b[0m (644.03 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> (8.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,257,984\u001b[0m (8.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491c8d05",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dea053d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.2,\n",
    "    patience=3,\n",
    "    min_lr=1e-6,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3e8286b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1751006849.874099  101156 service.cc:152] XLA service 0x7fb840002260 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1751006849.874158  101156 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 3050 Laptop GPU, Compute Capability 8.6\n",
      "2025-06-27 13:47:29.972310: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1751006850.546315  101156 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "2025-06-27 13:47:31.599332: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_4377_0', 464 bytes spill stores, 1372 bytes spill loads\n",
      "\n",
      "2025-06-27 13:47:31.658544: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_4377', 204 bytes spill stores, 204 bytes spill loads\n",
      "\n",
      "2025-06-27 13:47:32.188652: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_4377', 5356 bytes spill stores, 5416 bytes spill loads\n",
      "\n",
      "2025-06-27 13:47:32.234272: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_4377', 5216 bytes spill stores, 5212 bytes spill loads\n",
      "\n",
      "2025-06-27 13:47:32.266405: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_6702', 32 bytes spill stores, 32 bytes spill loads\n",
      "\n",
      "2025-06-27 13:47:32.312984: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_6702', 40 bytes spill stores, 40 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 2/71\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 106ms/step - accuracy: 0.1094 - loss: 0.7849 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1751006859.267051  101156 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m70/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4572 - loss: 0.4334"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-27 13:47:42.717577: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_4377', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n",
      "2025-06-27 13:47:42.982314: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_4377', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2025-06-27 13:47:43.189646: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_4377_0', 184 bytes spill stores, 520 bytes spill loads\n",
      "\n",
      "2025-06-27 13:47:43.360894: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_4377', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2025-06-27 13:47:43.401241: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_4377', 112 bytes spill stores, 112 bytes spill loads\n",
      "\n",
      "2025-06-27 13:47:43.772895: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_4377', 5020 bytes spill stores, 5060 bytes spill loads\n",
      "\n",
      "2025-06-27 13:47:43.823410: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_4377', 4960 bytes spill stores, 4960 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 0.4586 - loss: 0.4323"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-27 13:47:52.474126: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1188', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2025-06-27 13:47:52.653350: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1181', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2025-06-27 13:47:52.747222: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1181', 220 bytes spill stores, 220 bytes spill loads\n",
      "\n",
      "2025-06-27 13:47:52.987751: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1181_0', 480 bytes spill stores, 1372 bytes spill loads\n",
      "\n",
      "2025-06-27 13:47:53.259925: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1181', 5332 bytes spill stores, 5316 bytes spill loads\n",
      "\n",
      "2025-06-27 13:47:53.446195: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1181', 5356 bytes spill stores, 5412 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 276ms/step - accuracy: 0.4601 - loss: 0.4313 - val_accuracy: 0.6536 - val_loss: 0.2898 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.6629 - loss: 0.2797 - val_accuracy: 0.6856 - val_loss: 0.2714 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.7122 - loss: 0.2532 - val_accuracy: 0.6892 - val_loss: 0.2612 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.7446 - loss: 0.2260 - val_accuracy: 0.7158 - val_loss: 0.2505 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.7748 - loss: 0.2093 - val_accuracy: 0.7194 - val_loss: 0.2468 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.7900 - loss: 0.1966 - val_accuracy: 0.7140 - val_loss: 0.2472 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.7963 - loss: 0.1817 - val_accuracy: 0.7087 - val_loss: 0.2479 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8077 - loss: 0.1755\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.8077 - loss: 0.1756 - val_accuracy: 0.7105 - val_loss: 0.2486 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.8117 - loss: 0.1643 - val_accuracy: 0.7442 - val_loss: 0.2361 - learning_rate: 2.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.8284 - loss: 0.1547 - val_accuracy: 0.7407 - val_loss: 0.2356 - learning_rate: 2.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.8365 - loss: 0.1526 - val_accuracy: 0.7496 - val_loss: 0.2357 - learning_rate: 2.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.8471 - loss: 0.1469 - val_accuracy: 0.7513 - val_loss: 0.2346 - learning_rate: 2.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.8329 - loss: 0.1444 - val_accuracy: 0.7513 - val_loss: 0.2352 - learning_rate: 2.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.8395 - loss: 0.1413 - val_accuracy: 0.7460 - val_loss: 0.2357 - learning_rate: 2.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8380 - loss: 0.1404\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.8380 - loss: 0.1404 - val_accuracy: 0.7496 - val_loss: 0.2360 - learning_rate: 2.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.8468 - loss: 0.1368 - val_accuracy: 0.7531 - val_loss: 0.2336 - learning_rate: 4.0000e-05\n",
      "Epoch 17/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.8440 - loss: 0.1360 - val_accuracy: 0.7513 - val_loss: 0.2336 - learning_rate: 4.0000e-05\n",
      "Epoch 18/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.8561 - loss: 0.1337 - val_accuracy: 0.7513 - val_loss: 0.2333 - learning_rate: 4.0000e-05\n",
      "Epoch 19/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.8587 - loss: 0.1324 - val_accuracy: 0.7531 - val_loss: 0.2333 - learning_rate: 4.0000e-05\n",
      "Epoch 20/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.8453 - loss: 0.1338 - val_accuracy: 0.7549 - val_loss: 0.2333 - learning_rate: 4.0000e-05\n",
      "Epoch 21/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8493 - loss: 0.1332\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.8493 - loss: 0.1333 - val_accuracy: 0.7496 - val_loss: 0.2335 - learning_rate: 4.0000e-05\n",
      "Epoch 22/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.8494 - loss: 0.1342 - val_accuracy: 0.7496 - val_loss: 0.2334 - learning_rate: 8.0000e-06\n",
      "Epoch 23/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.8448 - loss: 0.1327 - val_accuracy: 0.7478 - val_loss: 0.2335 - learning_rate: 8.0000e-06\n",
      "Epoch 24/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8644 - loss: 0.1306\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.8643 - loss: 0.1307 - val_accuracy: 0.7478 - val_loss: 0.2335 - learning_rate: 8.0000e-06\n",
      "Epoch 25/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.8664 - loss: 0.1298 - val_accuracy: 0.7478 - val_loss: 0.2336 - learning_rate: 1.6000e-06\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=50,\n",
    "    callbacks=[early_stop, reduce_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7d470a",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b334b084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 174ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        acne       0.90      0.88      0.89       232\n",
      "    darkspot       0.17      0.02      0.04        48\n",
      "         dry       0.85      0.59      0.70       103\n",
      "      normal       0.78      0.76      0.77       143\n",
      "        oily       0.72      0.50      0.59       102\n",
      "       other       0.00      0.00      0.00         2\n",
      "     wrinkle       1.00      0.02      0.05        43\n",
      "\n",
      "   micro avg       0.83      0.63      0.72       673\n",
      "   macro avg       0.63      0.40      0.43       673\n",
      "weighted avg       0.79      0.63      0.67       673\n",
      " samples avg       0.73      0.69      0.70       673\n",
      "\n",
      "\n",
      "🔍 Confusion Matrix for 'acne':\n",
      "[[308  23]\n",
      " [ 28 204]]\n",
      "\n",
      "🔍 Confusion Matrix for 'darkspot':\n",
      "[[510   5]\n",
      " [ 47   1]]\n",
      "\n",
      "🔍 Confusion Matrix for 'dry':\n",
      "[[449  11]\n",
      " [ 42  61]]\n",
      "\n",
      "🔍 Confusion Matrix for 'normal':\n",
      "[[390  30]\n",
      " [ 34 109]]\n",
      "\n",
      "🔍 Confusion Matrix for 'oily':\n",
      "[[441  20]\n",
      " [ 51  51]]\n",
      "\n",
      "🔍 Confusion Matrix for 'other':\n",
      "[[561   0]\n",
      " [  2   0]]\n",
      "\n",
      "🔍 Confusion Matrix for 'wrinkle':\n",
      "[[520   0]\n",
      " [ 42   1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-27 13:49:23.519596: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "/home/ajusd/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ajusd/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, multilabel_confusion_matrix\n",
    "\n",
    "# Predict on validation set\n",
    "y_pred_prob = model.predict(val_ds)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)  # thresholding for multi-label\n",
    "\n",
    "# Ground truth labels\n",
    "y_true = np.concatenate([y for _, y in val_ds], axis=0)\n",
    "\n",
    "# Print classification report per label\n",
    "print(classification_report(y_true, y_pred, target_names=mlb.classes_))\n",
    "\n",
    "# Optional: confusion matrix per label\n",
    "conf_matrix = multilabel_confusion_matrix(y_true, y_pred)\n",
    "\n",
    "for i, label in enumerate(mlb.classes_):\n",
    "    print(f\"\\n🔍 Confusion Matrix for '{label}':\\n{conf_matrix[i]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc4171e",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea1c265d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "normal: 50.40%\n",
      "acne: 22.28%\n",
      "darkspot: 9.87%\n"
     ]
    }
   ],
   "source": [
    "def load_image_test(img_path):\n",
    "    img = tf.io.read_file(img_path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(img, IMG_SIZE)\n",
    "    img = img / 255.0\n",
    "    img = tf.expand_dims(img, axis=0)  # 👈 Add batch dimension\n",
    "    return img\n",
    "\n",
    "img_acne = load_image_test('test_detection/acne_test.jpeg')  # Make sure the filename has the correct extension\n",
    "y_test = model.predict(img_acne)\n",
    "\n",
    "# Get top 3 predictions (no thresholding)\n",
    "top_indices = y_test[0].argsort()[-3:][::-1]  # top 3 indices in descending order\n",
    "top_labels = [(mlb.classes_[i], y_test[0][i]) for i in top_indices]\n",
    "\n",
    "# Print predictions\n",
    "for label, prob in top_labels:\n",
    "    print(f\"{label}: {prob * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9079f967",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5b1a1b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "acne: 55.81%\n",
      "wrinkle: 23.62%\n",
      "oily: 18.89%\n"
     ]
    }
   ],
   "source": [
    "img_oily = load_image_test('test_detection/oily_test.jpeg')  # Make sure the filename has the correct extension\n",
    "y_test = model.predict(img_oily)\n",
    "\n",
    "# Get top 3 predictions (no thresholding)\n",
    "top_indices = y_test[0].argsort()[-3:][::-1]  # top 3 indices in descending order\n",
    "top_labels = [(mlb.classes_[i], y_test[0][i]) for i in top_indices]\n",
    "\n",
    "# Print predictions\n",
    "for label, prob in top_labels:\n",
    "    print(f\"{label}: {prob * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b66ac4b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "oily: 76.96%\n",
      "wrinkle: 22.05%\n",
      "acne: 9.31%\n"
     ]
    }
   ],
   "source": [
    "img_oily = load_image_test('test_detection/oily_test2.jpg')  # Make sure the filename has the correct extension\n",
    "y_test = model.predict(img_oily)\n",
    "\n",
    "# Get top 3 predictions (no thresholding)\n",
    "top_indices = y_test[0].argsort()[-3:][::-1]  # top 3 indices in descending order\n",
    "top_labels = [(mlb.classes_[i], y_test[0][i]) for i in top_indices]\n",
    "\n",
    "# Print predictions\n",
    "for label, prob in top_labels:\n",
    "    print(f\"{label}: {prob * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90ba052c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "normal: 62.10%\n",
      "dry: 11.66%\n",
      "darkspot: 5.08%\n"
     ]
    }
   ],
   "source": [
    "img_oily = load_image_test('test_detection/image_test.jpeg')  # Make sure the filename has the correct extension\n",
    "y_test = model.predict(img_oily)\n",
    "\n",
    "# Get top 3 predictions (no thresholding)\n",
    "top_indices = y_test[0].argsort()[-3:][::-1]  # top 3 indices in descending order\n",
    "top_labels = [(mlb.classes_[i], y_test[0][i]) for i in top_indices]\n",
    "\n",
    "# Print predictions\n",
    "for label, prob in top_labels:\n",
    "    print(f\"{label}: {prob * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b188059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "dry: 66.80%\n",
      "acne: 29.14%\n",
      "oily: 26.55%\n"
     ]
    }
   ],
   "source": [
    "img_wrinkle = load_image_test('test_detection/wrinkle_test.jpeg')  # Make sure the filename has the correct extension\n",
    "y_test = model.predict(img_wrinkle)\n",
    "\n",
    "# Get top 3 predictions (no thresholding)\n",
    "top_indices = y_test[0].argsort()[-3:][::-1]  # top 3 indices in descending order\n",
    "top_labels = [(mlb.classes_[i], y_test[0][i]) for i in top_indices]\n",
    "\n",
    "# Print predictions\n",
    "for label, prob in top_labels:\n",
    "    print(f\"{label}: {prob * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3966bf78",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "27ab5787",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('classify.keras')  # Save in new Keras 3 format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aea1d4e",
   "metadata": {},
   "source": [
    "## Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "498b4c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = tf.keras.models.load_model('classify.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "57c32054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "dry: 66.80%\n",
      "acne: 29.14%\n",
      "oily: 26.55%\n"
     ]
    }
   ],
   "source": [
    "img_wrinkle = load_image_test('test_detection/wrinkle_test.jpeg')  # Make sure the filename has the correct extension\n",
    "y_test = loaded_model.predict(img_wrinkle)\n",
    "\n",
    "# Get top 3 predictions (no thresholding)\n",
    "top_indices = y_test[0].argsort()[-3:][::-1]  # top 3 indices in descending order\n",
    "top_labels = [(mlb.classes_[i], y_test[0][i]) for i in top_indices]\n",
    "\n",
    "# Print predictions\n",
    "for label, prob in top_labels:\n",
    "    print(f\"{label}: {prob * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6246bf6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "dry: 65.53%\n",
      "wrinkle: 24.63%\n",
      "normal: 16.20%\n"
     ]
    }
   ],
   "source": [
    "img_wrinkle = load_image_test('test_detection/wrinkle2_test.jpg')  # Make sure the filename has the correct extension\n",
    "y_test = loaded_model.predict(img_wrinkle)\n",
    "\n",
    "# Get top 3 predictions (no thresholding)\n",
    "top_indices = y_test[0].argsort()[-3:][::-1]  # top 3 indices in descending order\n",
    "top_labels = [(mlb.classes_[i], y_test[0][i]) for i in top_indices]\n",
    "\n",
    "# Print predictions\n",
    "for label, prob in top_labels:\n",
    "    print(f\"{label}: {prob * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ac7fd56d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['acne', 'darkspot', 'dry', 'normal', 'oily', 'other', 'wrinkle'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "813fa17c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    }
   ],
   "source": [
    "model.save(\"classify2.keras\", save_format=\"keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5aea919a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save(\"classify.h5\")  # Save in HDF5 format"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
